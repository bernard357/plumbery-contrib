---

information:
  - "GlusterFS cluster of 3 nodes"

parameters:

  locationId:
    information:
      - "the primary data centre for this deployment"
    type: locations.list
    default: EU6

  domainName:
    information:
      - "the name of the network domain to be deployed"
    type: str
    default: GlusterfsFox

  networkName:
    information:
      - "the name of the Ethernet VLAN to be deployed"
    type: str
    default: GlusterfsNetwork

  diskPerNode:
    information:
      - "the quantity of storage given to each GlusterFS brick, in GB"
    type: [100..1000]
    default: 100

links:
  documentation: https://github.com/DimensionDataCBUSydney/plumbery-contrib/tree/master/fittings/storage/glusterfs
  credit: http://gluster.readthedocs.io/en/latest/Quick-Start-Guide/Quickstart/

defaults:

  domain:
    name: "{{ parameter.domainName }}"
    ipv4: auto

  ethernet:
    name: "{{ parameter.networkName }}"
    subnet: 192.168.20.0

  glusterfs-node:

    information:
      - "GlusterFS node"
      - "ssh centos@{{ node.public }}"
      - "sudo gluster volume info"
      - "sudo gluster peer status"

    appliance: 'CentOS 7'
    cpu: 2
    memory: 8

    disks:
      - "1 {{ parameter.diskPerNode }} economy"
      - "2 {{ parameter.diskPerNode }} economy"

    monitoring: essentials

    glue:
      - internet 22

  cloud-config:

    packages:
      - ntp

    write_files:

      - path: /root/hosts.awk
        content: |
          #!/usr/bin/awk -f
          /^{{ gluster-node1.private }}/ {next}
          /^{{ gluster-node2.private }}/ {next}
          /^{{ gluster-node3.private }}/ {next}
          {print}
          END {
           print "{{ gluster-node1.private }}    gluster-node1"
           print "{{ gluster-node2.private }}    gluster-node2"
           print "{{ gluster-node3.private }}    gluster-node3"
          }

      - path: /root/set_vdisk.sh
        content: |
          #!/usr/bin/env bash
          if [ -z "$(blkid ${1})" ];
          then
              echo "===== Formatting ${1}"
              mkfs -t ${2} ${1}
          fi
          UUID=$(blkid ${1} | sed -n 's/.*UUID=\"\([^\"]*\)\".*/\1/p')

          if ! grep -q "${UUID}" /etc/fstab; then
              echo "===== Adding ${1} to fstab"
              LINE="UUID=\"${UUID}\"\t${3}\t${2}\tnoatime,nodiratime,nodev,noexec,nosuid\t1 2"
              echo -e "${LINE}" >> /etc/fstab
          fi

          echo "===== Mounting ${3}"
          [ -d "${3}" ] || mkdir -p "${3}"
          mount "${3}"

    runcmd:

      - echo "===== Updating /etc/hosts"
      - cp -n /etc/hosts /etc/hosts.original
      - awk -f /root/hosts.awk /etc/hosts >/etc/hosts.new && mv /etc/hosts.new /etc/hosts

      - echo "===== Handling centos identity"
      - cp -n /etc/ssh/ssh_host_rsa_key /home/centos/.ssh/id_rsa
      - cp -n /etc/ssh/ssh_host_rsa_key.pub /home/centos/.ssh/id_rsa.pub
      - chown centos:centos /home/centos/.ssh/*

      - echo "===== Installing GlusterFS"
      - yum update -y
      - yum install -y centos-release-gluster
      - yum install -y glusterfs-server samba

      - echo "===== Starting GlusterFS daemon"
      - systemctl enable glusterd
      - systemctl start glusterd
      - systemctl status glusterd

      - echo "===== Configuring local storage for GlusterFS"
      - chmod +x /root/set_vdisk.sh

      - pvcreate /dev/sdb
      - vgcreate vg_brick1 /dev/sdb
      - lvcreate -l 100%FREE -n brick1 vg_brick1
      - /root/set_vdisk.sh /dev/vg_brick1/brick1 xfs /bricks/brick1
      - mkdir /bricks/brick1/volume1

      - pvcreate /dev/sdc
      - vgcreate vg_brick2 /dev/sdc
      - lvcreate -l 100%FREE -n brick2 vg_brick2
      - /root/set_vdisk.sh /dev/vg_brick2/brick2 xfs /bricks/brick2
      - mkdir /bricks/brick2/volume2

    ssh_keys:
      rsa_private: |
        {{ rsa_private.key }}
      rsa_public: "{{ rsa_public.key }}"

    users:
      - default

      - name: centos
        sudo: 'ALL=(ALL) NOPASSWD:ALL'
        ssh-authorized-keys:
          - "{{ rsa_public.key }}"
          - "{{ rsa_public.local }}"

      - name: root
        sudo: 'ALL=(ALL) NOPASSWD:ALL'
        ssh-authorized-keys:
          - "{{ rsa_public.key }}"
          - "{{ rsa_public.local }}"

    disable_root: false
    ssh_pwauth: false

---

locationId: "{{ parameter.locationId }}"

blueprints:

  - glusterfs:

      nodes:

        - gluster-node1:
            default: glusterfs-node

            cloud-config:

              runcmd:

                - echo "===== Configuring the GlusterFS trusted pool"
                - sleep 2m
                - gluster peer probe gluster-node2

                - echo "===== Creating shared volume"
                - sleep 1m
                - gluster volume create volume1 replica 2 gluster-node1:/bricks/brick1/volume1 gluster-node2:/bricks/brick1/volume1

                - echo "===== Starting shared volume"
                - gluster volume start volume1

                - echo "===== Checking volume information"
                - gluster volume info

                - echo "===== Testing shared volume"
                - mount -t glusterfs gluster-node1:/volume1 /mnt
                - echo "hello world" | tee /mnt/welcome.txt
                - cat /bricks/brick1/volume1/welcome.txt

                - echo "===== Expanding the cluster"
                - gluster peer probe gluster-node3
                - sleep 30
                - gluster volume add-brick volume1 replica 3 gluster-node3:/bricks/brick1/volume1

                - echo "===== Adding another volume"
                - gluster volume create volume2 replica 3 gluster-node1:/bricks/brick2/volume2 gluster-node2:/bricks/brick2/volume2 gluster-node3:/bricks/brick2/volume2
                - gluster volume start volume2

                - echo "===== Checking cluster status"
                - gluster volume info
                - gluster peer status

        - gluster-node2:
            default: glusterfs-node

            cloud-config:

              runcmd:

                - echo "===== Configuring the GlusterFS trusted pool"
                - sleep 2m
                - gluster peer probe gluster-node1

        - gluster-node3:
            default: glusterfs-node
